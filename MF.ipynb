{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0' :\n",
    "    raise SystemError('GPU device not found')\n",
    "print(f'Found GPU at: {device_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4589645293125753446\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2255906407\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14300509459699643347\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD를 사용한 MF 기본 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('./data/u.data', names=r_cols, sep='\\t', encoding='latin-1')\n",
    "ratings = ratings[['user_id', 'movie_id', 'rating']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; Train RMSE = 0.9585\n",
      "Iteration: 20 ; Train RMSE = 0.9373\n",
      "Iteration: 30 ; Train RMSE = 0.9280\n",
      "Iteration: 40 ; Train RMSE = 0.9225\n",
      "Iteration: 50 ; Train RMSE = 0.9183\n",
      "Iteration: 60 ; Train RMSE = 0.9145\n",
      "Iteration: 70 ; Train RMSE = 0.9100\n",
      "Iteration: 80 ; Train RMSE = 0.9039\n",
      "Iteration: 90 ; Train RMSE = 0.8953\n",
      "Iteration: 100 ; Train RMSE = 0.8833\n"
     ]
    }
   ],
   "source": [
    "# MF class\n",
    "class MF() : \n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True) : \n",
    "        self.R = np.array(ratings)\n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        # 아래는 파라미터로 받아본 변수를 클래스에 저장하는 부분\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta \n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    # RMSE 계산\n",
    "    def rmse(self) : \n",
    "        xs, ys = self.R.nonzero()\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x, y in zip(xs, ys) : \n",
    "            prediction = self.get_prediction(x, y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x,y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "     \n",
    "    def train(self) :\n",
    "        # 사용자-특징, 영화-특징 행렬 초기화\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K)) \n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K)) \n",
    "\n",
    "        # bias term 초기화\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "\n",
    "        # training samples의 리스트\n",
    "        rows, columns = self.R.nonzero()\n",
    "        # SGD를 적용할 대상(평점이 있는 요소의 인덱스와 평점)을 인덱스로 만들어 sample에 저장하기\n",
    "        self.samples = [(i, j, self.R[i,j]) for i, j in zip(rows, columns)]\n",
    "\n",
    "        # SGD\n",
    "        training_process = []\n",
    "        for i in range(self.iterations) : \n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse = self.rmse()\n",
    "            training_process.append((i+1, rmse))\n",
    "            if self.verbose : \n",
    "                if (i+1) % 10 == 0 : \n",
    "                    print('Iteration: %d ; Train RMSE = %.4f' % (i+1, rmse))\n",
    "        return training_process\n",
    "    \n",
    "    # 사용자 i와 아이템 j에 대한 평점 예측\n",
    "    def get_prediction(self, i, j) : \n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i,:].dot(self.Q[j,:].T)\n",
    "        return prediction\n",
    "    \n",
    "    # 최적화된 P와 Q 행렬을 얻기위한 SGD\n",
    "    def sgd(self) : \n",
    "        for i, j, r in self.samples : \n",
    "            prediction = self.get_prediction(i, j)\n",
    "            e = (r - prediction)\n",
    "            \n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "\n",
    "            self.P[i,:] += self.alpha * (e * self.Q[j,:] - self.beta * self.P[i,:])\n",
    "            self.Q[j,:] += self.alpha * (e * self.P[i,:] - self.beta * self.Q[j,:])\n",
    "\n",
    "# 전체 데이터 사용 MF\n",
    "R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "mf = MF(R_temp, K=30, alpha=0.001, beta=0.02, iterations=100, verbose=True) \n",
    "train_process = mf.train()   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train/test 분리 MF 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train tes 분리\n",
    "train_size = 0.75\n",
    "ratings = shuffle(ratings, random_state=1)\n",
    "# 전체 데이터 중 train_size 비율에 해당하는 데이터가 몇 개인지 계산\n",
    "cutoff = int(train_size * len(ratings))\n",
    "ratings_train = ratings.iloc[:cutoff]\n",
    "ratings_test = ratings.iloc[cutoff:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## New MF class for training & testing\n",
    "class NEW_MF() : \n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True) :\n",
    "        self.R = np.array(ratings)\n",
    "\n",
    "        # user_id, item_id를 R의 index와 매핑하기 위한 dictionary 생성\n",
    "        item_id_index = []\n",
    "        index_item_id = []\n",
    "        for i, one_id in enumerate(ratings) : \n",
    "            item_id_index.append([one_id, i])\n",
    "            index_item_id.append([i, one_id])\n",
    "        self.item_id_index = dict(item_id_index)\n",
    "        self.index_item_id = dict(index_item_id)\n",
    "        \n",
    "        user_id_index = []\n",
    "        index_user_id = []\n",
    "        for i, one_id in enumerate(ratings.T) : \n",
    "            user_id_index.append([one_id, i])\n",
    "            index_user_id.append([i, one_id])\n",
    "        self.user_id_index = dict(user_id_index)\n",
    "        self.index_user_id = dict(index_user_id)\n",
    "\n",
    "        # 아래는 파라미터로 받아본 변수를 클래스에 저장하는 부분\n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta \n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "\n",
    "     # train set의 RMSE 계산\n",
    "    def rmse(self) : \n",
    "        xs, ys = self.R.nonzero()\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x, y in zip(xs, ys) : \n",
    "            prediction = self.get_prediction(x, y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x,y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "        \n",
    "    # 사용자 i와 아이템 j에 대한 평점 예측\n",
    "    def get_prediction(self, i, j) :  \n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i,:].dot(self.Q[j,:].T)\n",
    "        return prediction\n",
    "        \n",
    "    # 최적화된 P와 Q 행렬을 얻기위한 SGD\n",
    "    def sgd(self) : \n",
    "        for i, j, r in self.samples : \n",
    "            prediction = self.get_prediction(i, j)\n",
    "            e = (r - prediction)\n",
    "            \n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "\n",
    "            self.P[i,:] += self.alpha * (e * self.Q[j,:] - self.beta * self.P[i,:])\n",
    "            self.Q[j,:] += self.alpha * (e * self.P[i,:] - self.beta * self.Q[j,:])\n",
    "\n",
    "    # test set을 설정하기\n",
    "    def set_test(self, ratings_test) : \n",
    "        test_set = []\n",
    "        for i in range(len(ratings_test)) : \n",
    "                # 현재 사용자의 인덱스\n",
    "                x = self.user_id_index[ratings_test.iloc[i,0]]\n",
    "                # 현재 아이템의 인덱스\n",
    "                y = self.item_id_index[ratings_test.iloc[i,1]]\n",
    "                # 현재 사용자-아이템의 평점\n",
    "                z = ratings_test.iloc[i,2]\n",
    "                test_set.append([x,y,z])\n",
    "                # test set을 R에서 지우고 학습시키기\n",
    "                self.R[x,y] = 0\n",
    "        self.test_set = test_set\n",
    "        return test_set\n",
    "        \n",
    "    # test set의 RMSE 계산하기\n",
    "    def test_rmse(self) : \n",
    "        error = 0\n",
    "        for one_set in self.test_set : \n",
    "            predicted = self.get_prediction(one_set[0], one_set[1])\n",
    "            error += pow(one_set[2] - predicted, 2)\n",
    "        return np.sqrt(error/len(self.test_set))\n",
    "        \n",
    "    # Training 하면서 test set의 정확도를 계산하기\n",
    "    def test(self) : \n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K)) \n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K)) \n",
    "        \n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "\n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i,j]) for i, j in zip(rows, columns)]\n",
    "        train_process = []\n",
    "        for i in range(self.iterations) : \n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            # train set에 대한 rmse\n",
    "            rmse1 = self.rmse()\n",
    "             # test set에 대한 rmse\n",
    "            rmse2 = self.test_rmse()\n",
    "            train_process.append((i+1, rmse1, rmse2))\n",
    "            if self.verbose : \n",
    "                if (i+1) % 10 == 0 : \n",
    "                    print('Iteration: %d ; Train RMSE = %.4f ; Test RMSE = %.4f' % (i+1, rmse1, rmse2))\n",
    "        return train_process\n",
    "        \n",
    "    # 사용자 id와 item id에 대한 평점\n",
    "    def get_one_prediction(self, user_id, item_id) : \n",
    "        return self.get_prediction(self.user_id_index[user_id], self.item_id_index[item_id])\n",
    "        \n",
    "    def full_prediction(self) : \n",
    "        return self.b + self.b_u[:,np.newaxis] + self.b_d[np.newaxis,:] + self.P.dot(self.Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; Train RMSE = 0.9659 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9409 ; Test RMSE = 0.9645\n",
      "Iteration: 30 ; Train RMSE = 0.9297 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9229 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9181 ; Test RMSE = 0.9496\n",
      "Iteration: 60 ; Train RMSE = 0.9141 ; Test RMSE = 0.9477\n",
      "Iteration: 70 ; Train RMSE = 0.9102 ; Test RMSE = 0.9462\n",
      "Iteration: 80 ; Train RMSE = 0.9058 ; Test RMSE = 0.9447\n",
      "Iteration: 90 ; Train RMSE = 0.9004 ; Test RMSE = 0.9431\n",
      "Iteration: 100 ; Train RMSE = 0.8934 ; Test RMSE = 0.9410\n"
     ]
    }
   ],
   "source": [
    "# Testing MF RMSE\n",
    "R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "mf = NEW_MF(R_temp, K=30, alpha=0.001, beta=0.02, iterations=100, verbose=True)\n",
    "test_set = mf.set_test(ratings_test)\n",
    "result = mf.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.90307585 3.38669898 3.07780667 ... 3.33220392 3.46303093 3.46211373]\n",
      " [3.94307314 3.49709478 3.14999954 ... 3.42395425 3.5459949  3.54632386]\n",
      " [3.31810624 2.88631858 2.553474   ... 2.82417622 2.94694006 2.93870246]\n",
      " ...\n",
      " [4.2008725  3.76239338 3.43669688 ... 3.70173748 3.82627205 3.82632411]\n",
      " [4.3549591  3.89865849 3.55773564 ... 3.83542055 3.94939181 3.94988627]\n",
      " [3.83929715 3.37313047 3.0540869  ... 3.29293751 3.42177767 3.41238174]]\n",
      "3.3866989775290346\n"
     ]
    }
   ],
   "source": [
    "# 예측 확인하기\n",
    "print(mf.full_prediction())\n",
    "print(mf.get_one_prediction(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MF의 최적 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 50\n",
      "Iteration: 10 ; Train RMSE = 0.9661 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9414 ; Test RMSE = 0.9645\n",
      "Iteration: 30 ; Train RMSE = 0.9305 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9241 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9197 ; Test RMSE = 0.9496\n",
      "Iteration: 60 ; Train RMSE = 0.9163 ; Test RMSE = 0.9478\n",
      "Iteration: 70 ; Train RMSE = 0.9133 ; Test RMSE = 0.9464\n",
      "Iteration: 80 ; Train RMSE = 0.9102 ; Test RMSE = 0.9452\n",
      "Iteration: 90 ; Train RMSE = 0.9065 ; Test RMSE = 0.9439\n",
      "Iteration: 100 ; Train RMSE = 0.9018 ; Test RMSE = 0.9423\n",
      "Iteration: 110 ; Train RMSE = 0.8953 ; Test RMSE = 0.9401\n",
      "Iteration: 120 ; Train RMSE = 0.8867 ; Test RMSE = 0.9373\n",
      "Iteration: 130 ; Train RMSE = 0.8757 ; Test RMSE = 0.9338\n",
      "Iteration: 140 ; Train RMSE = 0.8624 ; Test RMSE = 0.9300\n",
      "Iteration: 150 ; Train RMSE = 0.8475 ; Test RMSE = 0.9263\n",
      "Iteration: 160 ; Train RMSE = 0.8311 ; Test RMSE = 0.9231\n",
      "Iteration: 170 ; Train RMSE = 0.8133 ; Test RMSE = 0.9203\n",
      "Iteration: 180 ; Train RMSE = 0.7943 ; Test RMSE = 0.9182\n",
      "Iteration: 190 ; Train RMSE = 0.7741 ; Test RMSE = 0.9166\n",
      "Iteration: 200 ; Train RMSE = 0.7530 ; Test RMSE = 0.9157\n",
      "Iteration: 210 ; Train RMSE = 0.7313 ; Test RMSE = 0.9156\n",
      "Iteration: 220 ; Train RMSE = 0.7094 ; Test RMSE = 0.9161\n",
      "Iteration: 230 ; Train RMSE = 0.6876 ; Test RMSE = 0.9174\n",
      "Iteration: 240 ; Train RMSE = 0.6661 ; Test RMSE = 0.9191\n",
      "Iteration: 250 ; Train RMSE = 0.6453 ; Test RMSE = 0.9214\n",
      "Iteration: 260 ; Train RMSE = 0.6252 ; Test RMSE = 0.9241\n",
      "Iteration: 270 ; Train RMSE = 0.6059 ; Test RMSE = 0.9270\n",
      "Iteration: 280 ; Train RMSE = 0.5876 ; Test RMSE = 0.9302\n",
      "Iteration: 290 ; Train RMSE = 0.5702 ; Test RMSE = 0.9334\n",
      "Iteration: 300 ; Train RMSE = 0.5537 ; Test RMSE = 0.9367\n",
      "K = 60\n",
      "Iteration: 10 ; Train RMSE = 0.9662 ; Test RMSE = 0.9833\n",
      "Iteration: 20 ; Train RMSE = 0.9415 ; Test RMSE = 0.9644\n",
      "Iteration: 30 ; Train RMSE = 0.9307 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9243 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9201 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9168 ; Test RMSE = 0.9479\n",
      "Iteration: 70 ; Train RMSE = 0.9140 ; Test RMSE = 0.9465\n",
      "Iteration: 80 ; Train RMSE = 0.9111 ; Test RMSE = 0.9454\n",
      "Iteration: 90 ; Train RMSE = 0.9079 ; Test RMSE = 0.9442\n",
      "Iteration: 100 ; Train RMSE = 0.9037 ; Test RMSE = 0.9428\n",
      "Iteration: 110 ; Train RMSE = 0.8980 ; Test RMSE = 0.9409\n",
      "Iteration: 120 ; Train RMSE = 0.8903 ; Test RMSE = 0.9384\n",
      "Iteration: 130 ; Train RMSE = 0.8803 ; Test RMSE = 0.9351\n",
      "Iteration: 140 ; Train RMSE = 0.8681 ; Test RMSE = 0.9315\n",
      "Iteration: 150 ; Train RMSE = 0.8539 ; Test RMSE = 0.9278\n",
      "Iteration: 160 ; Train RMSE = 0.8382 ; Test RMSE = 0.9243\n",
      "Iteration: 170 ; Train RMSE = 0.8208 ; Test RMSE = 0.9212\n",
      "Iteration: 180 ; Train RMSE = 0.8018 ; Test RMSE = 0.9186\n",
      "Iteration: 190 ; Train RMSE = 0.7815 ; Test RMSE = 0.9167\n",
      "Iteration: 200 ; Train RMSE = 0.7600 ; Test RMSE = 0.9154\n",
      "Iteration: 210 ; Train RMSE = 0.7378 ; Test RMSE = 0.9148\n",
      "Iteration: 220 ; Train RMSE = 0.7152 ; Test RMSE = 0.9150\n",
      "Iteration: 230 ; Train RMSE = 0.6925 ; Test RMSE = 0.9159\n",
      "Iteration: 240 ; Train RMSE = 0.6700 ; Test RMSE = 0.9173\n",
      "Iteration: 250 ; Train RMSE = 0.6479 ; Test RMSE = 0.9193\n",
      "Iteration: 260 ; Train RMSE = 0.6265 ; Test RMSE = 0.9216\n",
      "Iteration: 270 ; Train RMSE = 0.6057 ; Test RMSE = 0.9242\n",
      "Iteration: 280 ; Train RMSE = 0.5858 ; Test RMSE = 0.9269\n",
      "Iteration: 290 ; Train RMSE = 0.5668 ; Test RMSE = 0.9299\n",
      "Iteration: 300 ; Train RMSE = 0.5487 ; Test RMSE = 0.9328\n",
      "K = 70\n",
      "Iteration: 10 ; Train RMSE = 0.9662 ; Test RMSE = 0.9833\n",
      "Iteration: 20 ; Train RMSE = 0.9416 ; Test RMSE = 0.9644\n",
      "Iteration: 30 ; Train RMSE = 0.9308 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9245 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9203 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9171 ; Test RMSE = 0.9479\n",
      "Iteration: 70 ; Train RMSE = 0.9144 ; Test RMSE = 0.9465\n",
      "Iteration: 80 ; Train RMSE = 0.9117 ; Test RMSE = 0.9454\n",
      "Iteration: 90 ; Train RMSE = 0.9086 ; Test RMSE = 0.9442\n",
      "Iteration: 100 ; Train RMSE = 0.9046 ; Test RMSE = 0.9428\n",
      "Iteration: 110 ; Train RMSE = 0.8992 ; Test RMSE = 0.9409\n",
      "Iteration: 120 ; Train RMSE = 0.8918 ; Test RMSE = 0.9383\n",
      "Iteration: 130 ; Train RMSE = 0.8822 ; Test RMSE = 0.9350\n",
      "Iteration: 140 ; Train RMSE = 0.8705 ; Test RMSE = 0.9314\n",
      "Iteration: 150 ; Train RMSE = 0.8570 ; Test RMSE = 0.9279\n",
      "Iteration: 160 ; Train RMSE = 0.8419 ; Test RMSE = 0.9247\n",
      "Iteration: 170 ; Train RMSE = 0.8253 ; Test RMSE = 0.9218\n",
      "Iteration: 180 ; Train RMSE = 0.8071 ; Test RMSE = 0.9193\n",
      "Iteration: 190 ; Train RMSE = 0.7874 ; Test RMSE = 0.9173\n",
      "Iteration: 200 ; Train RMSE = 0.7665 ; Test RMSE = 0.9160\n",
      "Iteration: 210 ; Train RMSE = 0.7447 ; Test RMSE = 0.9153\n",
      "Iteration: 220 ; Train RMSE = 0.7222 ; Test RMSE = 0.9152\n",
      "Iteration: 230 ; Train RMSE = 0.6994 ; Test RMSE = 0.9158\n",
      "Iteration: 240 ; Train RMSE = 0.6765 ; Test RMSE = 0.9169\n",
      "Iteration: 250 ; Train RMSE = 0.6538 ; Test RMSE = 0.9185\n",
      "Iteration: 260 ; Train RMSE = 0.6315 ; Test RMSE = 0.9205\n",
      "Iteration: 270 ; Train RMSE = 0.6098 ; Test RMSE = 0.9227\n",
      "Iteration: 280 ; Train RMSE = 0.5888 ; Test RMSE = 0.9252\n",
      "Iteration: 290 ; Train RMSE = 0.5686 ; Test RMSE = 0.9279\n",
      "Iteration: 300 ; Train RMSE = 0.5492 ; Test RMSE = 0.9306\n",
      "K = 80\n",
      "Iteration: 10 ; Train RMSE = 0.9663 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9417 ; Test RMSE = 0.9644\n",
      "Iteration: 30 ; Train RMSE = 0.9309 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9247 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9205 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9175 ; Test RMSE = 0.9479\n",
      "Iteration: 70 ; Train RMSE = 0.9149 ; Test RMSE = 0.9467\n",
      "Iteration: 80 ; Train RMSE = 0.9125 ; Test RMSE = 0.9456\n",
      "Iteration: 90 ; Train RMSE = 0.9098 ; Test RMSE = 0.9446\n",
      "Iteration: 100 ; Train RMSE = 0.9065 ; Test RMSE = 0.9435\n",
      "Iteration: 110 ; Train RMSE = 0.9020 ; Test RMSE = 0.9420\n",
      "Iteration: 120 ; Train RMSE = 0.8958 ; Test RMSE = 0.9399\n",
      "Iteration: 130 ; Train RMSE = 0.8874 ; Test RMSE = 0.9371\n",
      "Iteration: 140 ; Train RMSE = 0.8765 ; Test RMSE = 0.9336\n",
      "Iteration: 150 ; Train RMSE = 0.8636 ; Test RMSE = 0.9299\n",
      "Iteration: 160 ; Train RMSE = 0.8489 ; Test RMSE = 0.9262\n",
      "Iteration: 170 ; Train RMSE = 0.8328 ; Test RMSE = 0.9229\n",
      "Iteration: 180 ; Train RMSE = 0.8152 ; Test RMSE = 0.9201\n",
      "Iteration: 190 ; Train RMSE = 0.7960 ; Test RMSE = 0.9177\n",
      "Iteration: 200 ; Train RMSE = 0.7754 ; Test RMSE = 0.9159\n",
      "Iteration: 210 ; Train RMSE = 0.7535 ; Test RMSE = 0.9148\n",
      "Iteration: 220 ; Train RMSE = 0.7307 ; Test RMSE = 0.9143\n",
      "Iteration: 230 ; Train RMSE = 0.7073 ; Test RMSE = 0.9145\n",
      "Iteration: 240 ; Train RMSE = 0.6838 ; Test RMSE = 0.9154\n",
      "Iteration: 250 ; Train RMSE = 0.6604 ; Test RMSE = 0.9168\n",
      "Iteration: 260 ; Train RMSE = 0.6373 ; Test RMSE = 0.9188\n",
      "Iteration: 270 ; Train RMSE = 0.6148 ; Test RMSE = 0.9211\n",
      "Iteration: 280 ; Train RMSE = 0.5930 ; Test RMSE = 0.9237\n",
      "Iteration: 290 ; Train RMSE = 0.5720 ; Test RMSE = 0.9264\n",
      "Iteration: 300 ; Train RMSE = 0.5518 ; Test RMSE = 0.9293\n",
      "K = 90\n",
      "Iteration: 10 ; Train RMSE = 0.9663 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9417 ; Test RMSE = 0.9645\n",
      "Iteration: 30 ; Train RMSE = 0.9310 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9248 ; Test RMSE = 0.9524\n",
      "Iteration: 50 ; Train RMSE = 0.9207 ; Test RMSE = 0.9497\n",
      "Iteration: 60 ; Train RMSE = 0.9177 ; Test RMSE = 0.9480\n",
      "Iteration: 70 ; Train RMSE = 0.9152 ; Test RMSE = 0.9467\n",
      "Iteration: 80 ; Train RMSE = 0.9129 ; Test RMSE = 0.9457\n",
      "Iteration: 90 ; Train RMSE = 0.9104 ; Test RMSE = 0.9448\n",
      "Iteration: 100 ; Train RMSE = 0.9073 ; Test RMSE = 0.9437\n",
      "Iteration: 110 ; Train RMSE = 0.9033 ; Test RMSE = 0.9424\n",
      "Iteration: 120 ; Train RMSE = 0.8976 ; Test RMSE = 0.9405\n",
      "Iteration: 130 ; Train RMSE = 0.8898 ; Test RMSE = 0.9379\n",
      "Iteration: 140 ; Train RMSE = 0.8796 ; Test RMSE = 0.9346\n",
      "Iteration: 150 ; Train RMSE = 0.8671 ; Test RMSE = 0.9308\n",
      "Iteration: 160 ; Train RMSE = 0.8527 ; Test RMSE = 0.9271\n",
      "Iteration: 170 ; Train RMSE = 0.8369 ; Test RMSE = 0.9237\n",
      "Iteration: 180 ; Train RMSE = 0.8195 ; Test RMSE = 0.9208\n",
      "Iteration: 190 ; Train RMSE = 0.8006 ; Test RMSE = 0.9183\n",
      "Iteration: 200 ; Train RMSE = 0.7801 ; Test RMSE = 0.9162\n",
      "Iteration: 210 ; Train RMSE = 0.7582 ; Test RMSE = 0.9147\n",
      "Iteration: 220 ; Train RMSE = 0.7353 ; Test RMSE = 0.9138\n",
      "Iteration: 230 ; Train RMSE = 0.7117 ; Test RMSE = 0.9136\n",
      "Iteration: 240 ; Train RMSE = 0.6877 ; Test RMSE = 0.9139\n",
      "Iteration: 250 ; Train RMSE = 0.6637 ; Test RMSE = 0.9147\n",
      "Iteration: 260 ; Train RMSE = 0.6399 ; Test RMSE = 0.9161\n",
      "Iteration: 270 ; Train RMSE = 0.6166 ; Test RMSE = 0.9179\n",
      "Iteration: 280 ; Train RMSE = 0.5939 ; Test RMSE = 0.9200\n",
      "Iteration: 290 ; Train RMSE = 0.5721 ; Test RMSE = 0.9223\n",
      "Iteration: 300 ; Train RMSE = 0.5511 ; Test RMSE = 0.9248\n"
     ]
    }
   ],
   "source": [
    "## 최적의 K값 찾기\n",
    "results = []\n",
    "index = []\n",
    "# for K in range(50, 261, 10) : \n",
    "for K in range(50, 100, 10) : \n",
    "    print('K =', K)\n",
    "    R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "    mf = NEW_MF(R_temp, K=K, alpha=0.001, beta=0.02, iterations=300, verbose=True)\n",
    "    test_set = mf.set_test(ratings_test)\n",
    "    result = mf.test()\n",
    "    index.append(K)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 최적의 iterations 값 찾기\n",
    "summary = []\n",
    "for i in range(len(results)) : \n",
    "    RMSE = []\n",
    "    for result in results[i] : \n",
    "        RMSE.append(result[2])\n",
    "    min = np.min(RMSE)\n",
    "    j = RMSE.index(min)\n",
    "    summary.append([index[i], j+1, RMSE[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50, 208, 0.9155430144908261], [60, 213, 0.9148122030383211], [70, 216, 0.9151310340657888], [80, 222, 0.9142696350950047], [90, 231, 0.9135664712990477]]\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "plt.plot(index, [x[2] for x in summary])\n",
    "plt.ylim(0.89, 0.94)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
